---
tags:
  - linear-algebra
lang:
  - en
---

## Definition

Used to define complex systems.

$$\mathbb{R}^n \Rightarrow \text{vector with dimension n}$$

[[üëÅÔ∏è]] Note that:

$$\begin{bmatrix}
3 \\ 5
\end{bmatrix} \ne \begin{bmatrix}
5 \\ 3
\end{bmatrix}$$

while for sets:

$$\{1,2,2\} = \{1,2\}$$


## Operations

### Sum

$$\vec{v} + \vec{u} = \begin{bmatrix}
v_{x} + u_{x} \\
v_{y} + u_{y}
\end{bmatrix}$$

> üëÅÔ∏è also defined as the **diagonal of a parallelogram**

### Multiplication

Scalar product or _multiplo reale_

$$\vec{v} \cdot \vec{u} = \begin{bmatrix}
v_{x} \cdot u_{x} \\
v_{y} \cdot u_{y}
\end{bmatrix}$$

Vectors can be multiples of each other

$$k \cdot \vec{v} = \vec{u}$$

such that if $k=2$:

$$2\vec{v} = \vec{u}$$

$$\vec{v} = \frac{1}{2}\vec{u}$$

### Dot Product

Given vectors as input, it returns a number. It is defined as:

$$
\vec{v}, \vec{u} : \mathbb{R}^2 \implies \vec{v} \cdot \vec{u} = v_{a} \cdot u_{a} + v_{b} \cdot u_{b} \dots
$$

or

$$\vec{v} \cdot \vec{u} = ||\vec{v}|| \cdot ||\vec{u}|| \cdot \cos \alpha$$
$$\cos \alpha = \frac{\vec{v} \cdot \vec{u}}{||\vec{v}|| \cdot ||\vec{u}||}$$

dot product $< 0 \implies\theta \in \left] \frac{\pi}{2},\pi \right]$ angolo ottuso
dot product $> 0 \implies \theta \in \left[0, \frac{\pi}{2}\right[$ angolo actuo
dot product $= 0\implies \theta = \frac{\pi}{2}$ angolo retto

The dot product benefits of the commutative property.

### Module

Uses the Pythagorean Theorem and [[#Dot Product]] with $\alpha=0$ ($\cos 0 = 1$) to get the module (_length_) of the given vector.

$$\mathbb{R}^2 \implies ||\vec{v}|| = \sqrt{ v_{a} \cdot v_{b} } = \sqrt{ ||\vec{v}||^2 \cdot \cos 0} $$

### Cross Product

This operation is only valid in $\mathbb{R}^3$. The cross product $\times$ is defined as:

$$\begin{bmatrix}
x_{1} \\
x_{2} \\
x_{3}
\end{bmatrix}
\times
\begin{bmatrix}
y_{1} \\
y_{2} \\
y_{3}
\end{bmatrix}
=
\begin{bmatrix}
x_{2}y_{3} - x_{3}y_{2} \\
x_{3}y_{1} - x_{1}y_{3} \\
x_{1}y_{2} - x_{2}y_{1}
\end{bmatrix}$$

The result of this operation is a vector that is orthogonal to the plane generated by the two operands.

The cross product returns `0` when the two operands are [[#Linear Combination|Linearly dependent]].

Cross product **does not** benefit of the **commutative** property, it instead benefits of the anti commutative, such that:

$$\vec{a} \times \vec{b} = -(\vec{b} \times \vec{a})$$
It also does not benefit of the associative property:

$$\vec{a} \times (\vec{b} \times \vec{c}) \neq (\vec{a} \times \vec{b}) \times \vec{c}$$

#### In Vectorial Geometry

The cross product has a variety of uses in [[Vectorial Geometry#Cross Product in Vectorial Geometry|Vectorial Geometry]]. It is also used in the [[Vectorial Geometry#Cross Product Theorem|Cross Product Theorem]].

The direction of the vector generated by $\times$ is:

done on the right hand, if `dir a=thumb` and `dir b=index` then `dir result=middle finger`.
Otherwise, if `dir a=index` and `dir b=thumb` then`dir result=-middlefing`.

### Triple Product

The triple product is defined as:

$$
(\vec{a} \times \vec{b}) \cdot \vec{c}
$$

equally:

$$
||\vec{a} \times \vec{b}|| \cdot ||\vec{c}|| \cdot \cos \alpha
$$

where $||\vec{c}|| \cdot \cos \alpha$ is the projection of $\vec{c}$ onto $\vec{a} \times \vec{b}$.

#### In Vectorial Geometry

See uses in [[Vectorial Geometry#Triple Product in Vectorial Geometry|Vectorial Geometry]].

## Linear Combination

A vector can be defined as a multiple of $n$ vectors with parameters ${k,j,h,...}$ like so:
$$\vec{a} = k \vec{v} + j \vec{u}$$

Define $\vec{w}$ as a **LC** of $\vec{v}, \vec{u}, \vec{o}$: 

$$\begin{equation}
    \begin{cases}
kv_{x} + hu_{x} + jo_{x} = w_{x} \\
kv_{y} + hu_{y} + jo_{y} = w_{y} \\
kv_{z} + hu_{z} + jo_{z} = w_{z}
    \end{cases}
\end{equation}
$$

[[#Sum]] is always non parallel to each of the vectors and a LC of $h=1, j=1, k=1, \dots=1$

## Dependency

Two vectors are defined as **linearly dependent** if one can be expressed as a [[#Linear Combination]] of the other. Otherwise they are **linearly independent**.

### Sets and bases of $\mathbb{R}^n$

Having more vectors than $n$ in $\mathbb{R}^n$ guarantees that $N_{vecs} - n$ are [[#Dependency|linearly dependent]]. To create a valid base for $\mathbb{R}^n$ all vectors need to be [[#Dependency|linearly independent]] from each other. If any of the vectors can be expressed as a [[#Linear Combination]] of one, then the base will not be $\mathbb{R}^n$ but a [[#Dimension]] of $n$, where $n$ is the number of [[#Dependency|linearly independent]] vectors.

### Dimension

A sub-space contained in $\mathbb{R}^n$ of dimension $n - x$ where $n \gt x \ge 1$.

### [[üîé]] Examples

Given the set:

$$\begin{bmatrix}
1 \\
2 \\
3
\end{bmatrix},\begin{bmatrix}
4 \\
5 \\
6
\end{bmatrix},\begin{bmatrix}
7 \\
8 \\
8
\end{bmatrix}$$

This set of vectors can be used to define every vector of $\mathbb{R}^3$. They are all [[#Dependency|linearly independent]].

Given the set:

$$\begin{bmatrix}
1 \\
2 \\
3
\end{bmatrix},\begin{bmatrix}
4 \\
5 \\
6
\end{bmatrix},\begin{bmatrix}
7 \\
8 \\
8
\end{bmatrix},\begin{bmatrix}
2 \\
4 \\
6
\end{bmatrix}$$

Since $\mathbb{R}^3$ can be defined only with 3 vectors, any additional vector is by definition [[#Dependency|linearly dependent]].

Given the set:

$$\begin{bmatrix}
1 \\
2 \\
3
\end{bmatrix},\begin{bmatrix}
4 \\
5 \\
6
\end{bmatrix},\begin{bmatrix}
7 \\
8 \\
9
\end{bmatrix}$$

This vectors create a [[#Dimension]] of $n=2$ in a space of $\mathbb{R}^3$.

## Versor

A versor is a vector that has [[Vectors#Module|module]] **1**. To build a versor for a vector $\vec{x}$, this is valid:

$$\frac{1}{||x||}\vec{x}$$

[[üõ†Ô∏è]] Create a vector with mod $k$ from $\vec{v}$ keeping the same direction:

$$\left| \left| \frac{k}{||v||} \cdot v \right| \right| = |k|$$

## [[physics.index|Physics]]

$$\theta = \tan^{-1} \frac{\vec{a}_{y}}{\vec{a}_{x}}$$

## [[üõ†Ô∏è]] Applications

### Vector from $A$ to $B$

Given two points: $A, B \in \mathbb{R}$

$$\vec{AB} = \begin{bmatrix}
B_{x} - A_{x} \\
B_{y} - A_{y}
\end{bmatrix} = \begin{bmatrix}
\Delta x \\
\Delta y
\end{bmatrix}$$

This is also **true**:

$$\vec{A} + \vec{v} = B$$



### $x$ present in vector definition

1. Linear systems equation with rows not containing $x$
2. For [[#Dependency|LD]]: use the value obtained from using $h,k$
3. For [[#Dependency|LI]]: use any value $\ne$ from value obtained from using $h,k$ 
